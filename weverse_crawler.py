from urllib.parse import urlparse

from bs4 import BeautifulSoup
from playwright.async_api import async_playwright

from sns_info import SnsInfo, Profile


async def fetch_data(url: str) -> SnsInfo:
    """
    ä½¿ç”¨ Playwright éåŒæ­¥çˆ¬å– Weverse è²¼æ–‡è³‡æ–™

    Args:
        url: Weverse è²¼æ–‡ç¶²å€

    Returns:
        SnsInfo ç‰©ä»¶,åŒ…å«è²¼æ–‡è³‡è¨Š
    """
    async with async_playwright() as p:
        # å•Ÿå‹•ç€è¦½å™¨
        browser = await p.chromium.launch(
            headless=True,
            args=[
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-gpu',
            ]
        )

        # å‰µå»ºä¸Šä¸‹æ–‡
        context = await browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )

        # å‰µå»ºé é¢
        page = await context.new_page()

        try:
            # è¨ªå•é é¢
            await page.goto(url, wait_until='domcontentloaded', timeout=30000)

            # ç­‰å¾…é—œéµå…ƒç´ è¼‰å…¥
            await page.wait_for_selector('.WeverseViewer', timeout=30000)

            # ç²å–é é¢ HTML
            html = await page.content()

        finally:
            # ç¢ºä¿ç€è¦½å™¨é—œé–‰
            await browser.close()

    # ä½¿ç”¨ BeautifulSoup è§£æ HTML
    soup = BeautifulSoup(html, "lxml")

    # ç™¼æ–‡è€…é ­åƒ
    avatar_tag = soup.select_one(".avatar-decorator-_-avatar img")
    avatar_url = avatar_tag["src"] if avatar_tag else None

    # ç™¼æ–‡è€…åç¨±
    name_tag = soup.select_one(".avatar-decorator-_-title_area .avatar-decorator-_-title")
    author_name = name_tag.get_text(strip=True) if name_tag else None

    # ç™¼æ–‡å…§å®¹ï¼šæŠ“æ‰€æœ‰ p.pï¼Œä¿ç•™ <br> æ›è¡Œ
    text_blocks = []
    for p in soup.select("p.p"):
        text_blocks.append(p.get_text("\n", strip=True))
    post_text = "\n\n".join(text_blocks)

    # ç…§åŸå§‹é †åºæŠ“å–æ‰€æœ‰ WidgetMedia (ç…§ç‰‡å’Œå½±ç‰‡ç¸®åœ–)
    image_urls = []
    media_divs = soup.select("div.WidgetMedia")
    for div in media_divs:
        img_tag = div.find("img")
        if img_tag and img_tag.get("src"):
            image_urls.append(img_tag["src"])

    # å»é™¤ç¶²å€ query åƒæ•¸ï¼Œä¿æŒä¹¾æ·¨
    image_urls = [urlparse(link)._replace(query="").geturl() for link in image_urls]

    return SnsInfo(
        post_link=url,
        profile=Profile(name=author_name, url=avatar_url),
        content=post_text,
        images=image_urls
    )


# æ¸¬è©¦ç”¨
if __name__ == "__main__":
    import asyncio

    # æ¸¬è©¦ç¶²å€
    test_url = "https://weverse.io/stayc/artist/2-169128050"


    async def main():
        print("ğŸš€ é–‹å§‹çˆ¬å– Weverse è²¼æ–‡")
        try:
            result = await fetch_data(test_url)
            print("\nâœ… æˆåŠŸçˆ¬å–è³‡æ–™:")
            print(result)
        except Exception as e:
            print(f"\nâŒ çˆ¬å–å¤±æ•—: {e}")


    asyncio.run(main())
